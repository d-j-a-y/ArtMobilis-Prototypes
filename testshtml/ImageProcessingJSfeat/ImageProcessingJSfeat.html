<!DOCTYPE html>
<html>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<body>
    <script type="text/javascript" src="lib/jsfeat.js"></script>
    <script type="text/javascript" src="lib/compatibility.js"></script>
    <script type="text/javascript" src="lib/profiler.js"></script>

    <title>JSFeat - Exercice: extract edges</title>
    <h1>JSFeat - Exercice: extract edges</h1>

    <video id="webcam" style="display:none;" height="480" width="640"></video>
    <div style=" width:640px;height:480px;margin: 10px auto;">
        <canvas id="canvas" width="640" height="480"></canvas>
        <div id="log"></div>
    </div>

    <script>
        var video = document.getElementById('webcam');
        var canvas = document.getElementById('canvas');
        var log = document.getElementById('log');
        var stat = new profiler();
        var ctx;
        var img_u8;
        
        var height, width;
        
        height = 640;
        width = 480;

        // onload ask for camera and call demo_app
        window.onload = function () {

            compatibility.getUserMedia({ video: true }, function (stream) {
                try {
                    setTimeout(function () {
                        video.play();
                    }, 500);
                    video.src = compatibility.URL.createObjectURL(stream);
                    demo_app(video.videoWidth, video.videoHeight);
                } catch (error) {
                    video.src = stream;
                    console.log("error init");
                }
            }, function (error) {
                console.log("error gum");
            });

            // initialize the application
            function demo_app(videoWidth, videoHeight) {
                ctx = canvas.getContext('2d');

                img_u8 = new jsfeat.matrix_t(height, width, jsfeat.U8_t | jsfeat.C1_t);

                compatibility.requestAnimationFrame(tick);

                console.log("initialized");
                stat.add("grayscale");
                stat.add("rewrite");
            }

            // process each acquired image
            function tick() {
                compatibility.requestAnimationFrame(tick);
                stat.new_frame();
                if (video.readyState === video.HAVE_ENOUGH_DATA) {
                    ctx.drawImage(video, 0, 0, height, width);
                    var imageData = ctx.getImageData(0, 0, height, width);

                    // greyscale conversion
                    stat.start("grayscale");
                    // I should put my code here
						
						var gray_img = new jsfeat.matrix_t(width, height, jsfeat.U8_t | jsfeat.C1_t);
						jsfeat.imgproc.grayscale(imageData.data, width, height, gray_img, jsfeat.COLOR_RGBA2GRAY);






                    stat.stop("grayscale");

                    // render result back to canvas (Warning: format is RGBA)
                    stat.start("rewrite");
                    // I should put my code here
                    
                    
                    //TODO check data_u32
                    var data_u32 = new Uint32Array (imageData.data.buffer);
							var alpha = (0xff << 24); // opacity=1
                   
                    var i = gray_img.cols * gray_img.rows, pix = 0;
                    while (--i >= 0) {
                        pix = gray_img.data[i];
                        // write 4 channels: RGBA with GreyGreyGreyAlpha
                        data_u32[i] = alpha | (pix << 16) | (pix << 8) | pix;
                    }


                    stat.stop("rewrite");

                    ctx.putImageData(imageData, 0, 0);
                    log.innerHTML = stat.log();
                }
            }
        }
    </script>
</body>
</html>
